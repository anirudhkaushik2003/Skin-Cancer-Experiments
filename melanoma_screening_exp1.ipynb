{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25331\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import tqdm\n",
    "\n",
    "# Read image\n",
    "files  = sorted(glob.glob(\"/ssd_scratch/cvit/anirudhkaushik/dataset/ISIC_2019/ISIC_2019_Training_Input/*.jpg\"))\n",
    "print(len(files))\n",
    "# for f in tqdm.tqdm(files):\n",
    "#     img = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     # resize to 224x224\n",
    "#     img = cv2.resize(img, (224, 224),cv2.INTER_AREA )\n",
    "#     # save over original\n",
    "#     cv2.imwrite(f, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import ResNet101_Weights, resnet101\n",
    "\n",
    "# Load pretrained model\n",
    "# model = resnet101(weights=ResNet101_Weights.IMAGENET1K_V2)\n",
    "model = resnet101()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n",
      "0  ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "1  ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "2  ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "3  ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
      "4  ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"/ssd_scratch/cvit/anirudhkaushik/dataset/ISIC_2019/ISIC_2019_Training_GroundTruth.csv\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying color constancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_constancy(img, power=6, gamma=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    img: 3D np array\n",
    "        The original image with format of (h, w, c)\n",
    "    power: int\n",
    "        The degree of norm, 6 is used in reference paper\n",
    "    gamma: float\n",
    "        The value of gamma correction, 2.2 is used in reference paper\n",
    "    \"\"\"\n",
    "    img_dtype = img.dtype\n",
    "\n",
    "\n",
    "    if gamma is not None:\n",
    "        img = img.astype('uint8')\n",
    "        look_up_table = np.ones((256,1), dtype='uint8') * 0\n",
    "        for i in range(256): look_up_table[i][0] = 255*pow(i/255, 1/gamma)\n",
    "        img = cv2.LUT(img, look_up_table)\n",
    "\n",
    "\n",
    "    img = img.astype('float32')\n",
    "    img_power = np.power(img, power)\n",
    "    rgb_vec = np.power(np.mean(img_power, (0,1)), 1/power)\n",
    "    rgb_norm = np.sqrt(np.sum(np.power(rgb_vec, 2.0)))\n",
    "    rgb_vec = rgb_vec/rgb_norm\n",
    "    rgb_vec = 1/(rgb_vec*np.sqrt(3))\n",
    "    img = np.multiply(img, rgb_vec)\n",
    "    \n",
    "    return img.astype(img_dtype) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "def load_isic_2019(classes):\n",
    "    root = \"/ssd_scratch/cvit/anirudhkaushik/dataset/ISIC_2019\"\n",
    "    \"\"\"\n",
    "    Load ISIC_2019 dataset and convert it to IIRC format\n",
    "\n",
    "    Args:\n",
    "        root (string): The location of the dataset\n",
    "        intask_valid_train_ratio (float): the percentage of the training set to be taken for the in-task validation set\n",
    "            , a training-like validation set used for valdation during the task training (default: 0.1)\n",
    "        posttask_valid_train_ratio (float): the percentage of the training set to be taken for the post-task validation\n",
    "            set, a test-like validation set used for valdation after the task training (default: 0.1)\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, DatasetStructType]: datasets, a dictionary with the keys corresponding to the four splits (train,\n",
    "        intask_validation, posttask_validation, test), and the values being a list of the samples that belong to\n",
    "        each split (with the images provided in Image.Image type) in the DatasetTypeStruct structure\n",
    "    \"\"\"\n",
    "    raw_data_meta_df = pd.read_csv(root+'/ISIC_2019_Training_GroundTruth.csv')\n",
    "\n",
    "    isic_data_map = {\n",
    "        \"MEL\": \"Melanoma\",  \n",
    "        \"NV\": \"Melanocytic_nevus\" ,\n",
    "        \"BCC\": \"Basal_cell_carcinoma\",\n",
    "        \"AK\": \"Actinic_keratosis\",\n",
    "        \"BKL\": \"Benign_keratosis\",\n",
    "        \"DF\": \"Dermatofibroma\",\n",
    "        \"VASC\": \"Vascular_lesion\",\n",
    "        \"SCC\": \"Squamous_cell_carcinoma\"\n",
    "    }\n",
    "\n",
    "    train_data_classwise = {class_name: [] for class_name in classes}\n",
    "    test_data_classwise = {class_name: [] for class_name in classes}\n",
    "    \n",
    "    train_num_samples_per_class = {class_name: 0 for class_name in classes}\n",
    "    test_num_samples_per_class = {class_name: 0 for class_name in classes}\n",
    "    \n",
    "    labels = list(raw_data_meta_df.columns[1:-1])\n",
    "    class_to_idx = {isic_data_map[label]: idx for idx, label in enumerate(classes)}\n",
    "\n",
    "\n",
    "    X = raw_data_meta_df.iloc[:]['image'] # only image names, not actual images\n",
    "    y = raw_data_meta_df.iloc[:, 1:]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1, stratify=y)\n",
    "\n",
    "    raw_data_train = []\n",
    "    for ind  in range(len(X_train)):\n",
    "        img_name = X_train.iloc[ind]\n",
    "        labels = y_train.iloc[ind]\n",
    "        label = labels[labels == 1].index[0]\n",
    "        label_name = label\n",
    "        if label not in classes:\n",
    "            continue            \n",
    "        image = cv2.imread(os.path.join(root, \"ISIC_2019_Training_Input\", img_name+\".jpg\"), cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (224, 224), cv2.INTER_AREA) # remove later\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = color_constancy(image) \n",
    "        label = class_to_idx[isic_data_map[label]] \n",
    "        # raw_data_train.append((image, label))\n",
    "        train_data_classwise[label_name].append((image, label))\n",
    "\n",
    "\n",
    "    # Balance as per the class with minimum number of samples\n",
    "    min_num_samples = min([len(train_data_classwise[class_name]) for class_name in classes])\n",
    "    # randomly sample from other classes to make the number of samples equal to min_num_samples\n",
    "    for class_name in classes:\n",
    "        np.random.shuffle(train_data_classwise[class_name])\n",
    "        train_data_classwise[class_name] = train_data_classwise[class_name][:min_num_samples]\n",
    "        train_num_samples_per_class[class_name] = len(train_data_classwise[class_name])\n",
    "\n",
    "    print(\"Train data distribution\")\n",
    "    for class_name in classes:\n",
    "        label_name = isic_data_map[class_name]\n",
    "        print(\"{}: {}\".format(label_name, train_num_samples_per_class[class_name]))\n",
    "\n",
    "    # insert the samples into the raw_data_train fast\n",
    "    for class_name in classes:\n",
    "        raw_data_train.extend(train_data_classwise[class_name])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    raw_data_test = []\n",
    "    for ind  in range(len(X_test)):\n",
    "        img_name = X_test.iloc[ind]\n",
    "        labels = y_test.iloc[ind]\n",
    "        label = labels[labels == 1].index[0]\n",
    "        label_name = label\n",
    "        if label not in classes:\n",
    "            continue\n",
    "        image = cv2.imread(os.path.join(root, \"ISIC_2019_Training_Input\", img_name+\".jpg\"), cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (224, 224), cv2.INTER_AREA) # remove later, inter area is for making it smaller, for making it larger use inter linear\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = color_constancy(image) \n",
    "        label = class_to_idx[isic_data_map[label]]\n",
    "        # raw_data_test.append((image, label))\n",
    "        test_data_classwise[label_name].append((image, label))\n",
    "\n",
    "    # Balance as per the class with minimum number of samples\n",
    "    min_num_samples = min([len(test_data_classwise[class_name]) for class_name in classes])\n",
    "    # randomly sample from other classes to make the number of samples equal to min_num_samples\n",
    "    for class_name in classes:\n",
    "        np.random.shuffle(test_data_classwise[class_name])\n",
    "        test_data_classwise[class_name] = test_data_classwise[class_name][:min_num_samples]\n",
    "        test_num_samples_per_class[class_name] = len(test_data_classwise[class_name])\n",
    "\n",
    "    # insert the samples into the raw_data_test fast\n",
    "    for class_name in classes:\n",
    "        raw_data_test.extend(test_data_classwise[class_name])\n",
    "\n",
    "    print(\"Test data distribution\")\n",
    "    for class_name in classes:\n",
    "        label_name = isic_data_map[class_name]\n",
    "        print(\"{}: {}\".format(label_name, test_num_samples_per_class[class_name]))\n",
    "\n",
    "    return raw_data_train, raw_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data distribution\n",
      "Melanoma: 4070\n",
      "Melanocytic_nevus: 4070\n",
      "Test data distribution\n",
      "Melanoma: 452\n",
      "Melanocytic_nevus: 452\n",
      "Train data distribution\n",
      "Melanoma: 2361\n",
      "Benign_keratosis: 2361\n",
      "Test data distribution\n",
      "Melanoma: 263\n",
      "Benign_keratosis: 263\n",
      "Train data distribution\n",
      "Melanoma: 2361\n",
      "Melanocytic_nevus: 2361\n",
      "Benign_keratosis: 2361\n",
      "Test data distribution\n",
      "Melanoma: 263\n",
      "Melanocytic_nevus: 263\n",
      "Benign_keratosis: 263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_nevus, test_nevus = load_isic_2019([\"MEL\", \"NV\"])\n",
    "train_bkl, test_bkl = load_isic_2019([\"MEL\", \"BKL\"])\n",
    "final_train, final_test = load_isic_2019([\"MEL\", \"NV\", \"BKL\"])\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"/ssd_scratch/cvit/anirudhkaushik/saved_models/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melanoma vs Nevus \n",
    " *Note: this model was trained with dysplastic Nevus (suspected) trained without color constancy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "melanoma_vs_nevus_model = resnet101()\n",
    "melanoma_vs_nevus_model.fc = nn.Linear(2048, 2)\n",
    "melanoma_vs_nevus_model.load_state_dict(torch.load(os.path.join(base_model_path, \"dysplastic_nevus_exp2.pth\")))\n",
    "melanoma_vs_nevus_model = torch.nn.DataParallel(model)\n",
    "melanoma_vs_nevus_model = melanoma_vs_nevus_model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melanoma vs Seborrheic Keratosis\n",
    "*Note: this model wil be trained from scratch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "melanoma_vs_benign_keratosis_model = resnet101()\n",
    "melanoma_vs_benign_keratosis_model.fc = nn.Linear(2048, 2)\n",
    "melanoma_vs_benign_keratosis_model = torch.nn.DataParallel(model)\n",
    "melanoma_vs_benign_keratosis_model = melanoma_vs_benign_keratosis_model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model\n",
    "*Note: this model will be trained from scratch on all 3 classes jointly and will be used as a baseline for melanoma identification*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_nv_bkl_model = resnet101()\n",
    "mel_nv_bkl_model.fc = nn.Linear(2048, 3)\n",
    "mel_nv_bkl_model = torch.nn.DataParallel(model)\n",
    "mel_nv_bkl_model = mel_nv_bkl_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# dataloader\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "    \n",
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225] )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel vs nevus dataset and dataloader\n",
    "train_mel_vs_nevus_dataset = ISICDataset(train_nevus, transform=transform)\n",
    "test_mel_vs_nevus_dataset = ISICDataset(test_nevus, transform=transform)\n",
    "\n",
    "train_mel_vs_nevus_dataloader = DataLoader(train_mel_vs_nevus_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_mel_vs_nevus_dataloader = DataLoader(test_mel_vs_nevus_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# mel vs bkl dataset and dataloader\n",
    "train_mel_vs_bkl_dataset = ISICDataset(train_bkl, transform=transform)\n",
    "test_mel_vs_bkl_dataset = ISICDataset(test_bkl, transform=transform)\n",
    "\n",
    "train_mel_vs_bkl_dataloader = DataLoader(train_mel_vs_bkl_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_mel_vs_bkl_dataloader = DataLoader(test_mel_vs_bkl_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# final dataset and dataloader\n",
    "train_final_dataset = ISICDataset(final_train, transform=transform)\n",
    "test_final_dataset = ISICDataset(final_test, transform=transform)\n",
    "\n",
    "train_final_dataloader = DataLoader(train_final_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_final_dataloader = DataLoader(test_final_dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    print('\\nTest set: Accuracy: {:.0f}%\\n'.format(\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "def train_model(model, train_loader, test_loader, optimizer, epochs):\n",
    "    acc_list = []\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/100))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        acc = test_model(model, test_loader)\n",
    "        acc_list.append(acc)\n",
    "        loss_list.append(running_loss)\n",
    "\n",
    "    return acc_list, loss_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classwise_acc(model, test_loader, classes):\n",
    "    isic_data_map = {\n",
    "        \"MEL\": \"Melanoma\",  \n",
    "        \"NV\": \"Melanocytic_nevus\" ,\n",
    "        \"BCC\": \"Basal_cell_carcinoma\",\n",
    "        \"AK\": \"Actinic_keratosis\",\n",
    "        \"BKL\": \"Benign_keratosis\",\n",
    "        \"DF\": \"Dermatofibroma\",\n",
    "        \"VASC\": \"Vascular_lesion\",\n",
    "        \"SCC\": \"Squamous_cell_carcinoma\"\n",
    "    }\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "    # again no gradients needed\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "    return [correct_pred[isic_data_map[classname]] / total_pred[isic_data_map[classname]] for classname in classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_experiment(model, classes, train_dataloader, test_dataloader, save=False, save_path=None):\n",
    "\n",
    "    # train and test accuracy\n",
    "    acc_list, loss_list = train_model(model,train_dataloader,test_dataloader, optimizer, 14)\n",
    "    # plot accuracy and loss curves\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc_list)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss_list)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # print final test accuracy\n",
    "    final_test_acc_bkl = test_model(model, test_dataloader)\n",
    "    print(\"Final test accuracy: {:.0f}%\".format(100. * final_test_acc_bkl))\n",
    "\n",
    "    # print classwise accuracy\n",
    "    classwise_score = classwise_acc(model, test_dataloader, classes)\n",
    "    print(\"Melanoma class accuracy: {:.0f}%\".format(100. * classwise_score[0]))\n",
    "    print(\"Melanocytic Nevus class accuracy: {:.0f}%\".format(100. * classwise_score[1]))\n",
    "\n",
    "    # print mean and standard deviation of the training\n",
    "    # mean and standard deviation of accuracy \n",
    "    mean = np.mean(acc_list)\n",
    "    std = np.std(acc_list)\n",
    "    print(\"Mean accuracy: {:.2f}%\".format(100. * mean))\n",
    "    print(\"Standard deviation of accuracy: {:.2f}%\".format(100. * std))\n",
    "\n",
    "    if save:\n",
    "        torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin training Melanoma vs Benign keratosis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise_experiment(melanoma_vs_benign_keratosis_model,[\"MEL\", \"BKL\"] ,train_mel_vs_bkl_dataloader, test_mel_vs_bkl_dataloader, save=True, save_path=os.path.join(base_model_path, \"melanoma_screening_exp1_mel_vs_bkl.pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train final model \n",
    " - Trained on melanoma vs benign keratosis vs Nevus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise_experiment(mel_nv_bkl_model, [\"MEL\", \"NV\", \"BKL\"], train_final_dataloader, test_final_dataloader, save=True, save_path=os.path.join(base_model_path, \"melanoma_screening_exp1_mel_nv_bkl.pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0: \"Melanoma\", 1: \"Melanocytic Nevus\"}\n",
    "random_sampler = torch.utils.data.RandomSampler(test_dataset_refined_fixed, num_samples=10, replacement=False)\n",
    "# plot these 10 images with their labels in a grid\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, idx in enumerate(random_sampler):\n",
    "    img, label = test_dataset_refined_fixed[idx]\n",
    "    output = model(img.unsqueeze(0).to(device))\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    img = img.cpu().numpy()\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    # normalize\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(\"GT: {}\\nPred: {}\".format(classes[label], classes[pred.item()]))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
